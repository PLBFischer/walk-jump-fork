2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_setup.py:_flush():75] Loading settings from /n/home10/pafischer/.config/wandb/settings
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_setup.py:_flush():75] Loading settings from /n/netscratch/mahadevan_lab/Everyone/pafischer/walk-jump-fork/wandb/settings
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_setup.py:_flush():75] Loading settings from environment variables: {'api_key': '***REDACTED***', '_require_service': 'True'}
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_setup.py:_flush():75] Inferring run settings from compute environment: {'program_relpath': 'script_env_b_train.py', 'program': '/n/netscratch/mahadevan_lab/Everyone/pafischer/walk-jump-fork/script_env_b_train.py'}
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_init.py:_log_setup():386] Logging user logs to ./wandb/run-20250305_111314-plmxgxno/logs/debug.log
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_init.py:_log_setup():387] Logging internal logs to ./wandb/run-20250305_111314-plmxgxno/logs/debug-internal.log
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_init.py:init():420] calling init triggers
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_init.py:init():425] wandb.init called with sweep_config: {}
config: {}
2025-03-05 11:13:14,847 INFO    MainThread:2802357 [wandb_init.py:init():471] starting backend
2025-03-05 11:13:14,850 INFO    MainThread:2802357 [backend.py:_multiprocessing_setup():99] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-03-05 11:13:14,856 INFO    MainThread:2802357 [wandb_init.py:init():480] backend started and connected
2025-03-05 11:13:14,858 INFO    MainThread:2802357 [wandb_init.py:init():550] updated telemetry
2025-03-05 11:13:14,887 INFO    MainThread:2802357 [wandb_init.py:init():581] communicating current version
2025-03-05 11:13:14,951 INFO    MainThread:2802357 [wandb_init.py:init():586] got version response upgrade_message: "wandb version 0.19.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-03-05 11:13:14,952 INFO    MainThread:2802357 [wandb_init.py:init():596] communicating run to backend with 30 second timeout
2025-03-05 11:13:15,411 INFO    MainThread:2802357 [wandb_init.py:init():624] starting run threads in backend
2025-03-05 11:13:18,505 INFO    MainThread:2802357 [wandb_run.py:_console_start():1827] atexit reg
2025-03-05 11:13:18,507 INFO    MainThread:2802357 [wandb_run.py:_redirect():1701] redirect: SettingsConsole.WRAP
2025-03-05 11:13:18,507 INFO    MainThread:2802357 [wandb_run.py:_redirect():1738] Wrapping output streams.
2025-03-05 11:13:18,507 INFO    MainThread:2802357 [wandb_run.py:_redirect():1762] Redirects installed.
2025-03-05 11:13:18,508 INFO    MainThread:2802357 [wandb_init.py:init():651] run started, returning control to user process
2025-03-05 11:13:18,752 INFO    MainThread:2802357 [wandb_run.py:_config_callback():966] config_cb None None {'cfg': {'dryrun': False, 'data': {'_target_': 'walkjump.data.AbDataModule', 'csv_data_path': '/n/netscratch/mahadevan_lab/Everyone/pafischer/walk-jump-fork/running_csv.csv', 'batch_size': 64, 'num_workers': 1}, 'model': {'model_cfg': {'arch': {'_target_': 'walkjump.model.arch.ByteNetArch', 'n_tokens': 20, 'd_model': 128, 'n_layers': 35, 'kernel_size': 3, 'max_dilation': 128, 'slim': True, 'activation': 'silu', 'final_layernorm': True}, 'hyperparameters': {'lr': 0.0001, 'weight_decay': 0.01, 'sigma': 1.0, 'warmup_batches': 1, 'lr_start_factor': 0.1}}, '_target_': 'walkjump.model.DenoiseModel'}, 'callbacks': {'model_checkpoint': {'_target_': 'lightning.pytorch.callbacks.ModelCheckpoint', 'dirpath': 'checkpoints', 'filename': '{epoch}-{step}-{val_loss:.4f}', 'monitor': 'val_loss', 'save_top_k': -1, 'mode': 'min', 'verbose': True, 'save_last': True}, 'early_stopping': {'_target_': 'lightning.pytorch.callbacks.EarlyStopping', 'monitor': 'val_loss', 'min_delta': 0, 'patience': 3, 'mode': 'min'}, 'lr_monitor': {'_target_': 'lightning.pytorch.callbacks.LearningRateMonitor', 'logging_interval': 'step'}}, 'logger': {'_target_': 'lightning.pytorch.loggers.WandbLogger', 'save_dir': '.', 'offline': False, 'project': None, 'entity': None, 'group': None, 'notes': None, 'tags': None}, 'trainer': {'_target_': 'lightning.pytorch.Trainer', 'accelerator': 'gpu', 'devices': 1, 'num_nodes': 1, 'accumulate_grad_batches': 1, 'gradient_clip_val': 0.0, 'gradient_clip_algorithm': 'norm', 'precision': 32, 'max_epochs': 20, 'max_steps': -1, 'val_check_interval': 0.99}, 'setup': {'torch': {'_target_': 'torch.set_float32_matmul_precision', 'precision': 'medium'}, 'seed': {'_target_': 'lightning.pytorch.seed_everything', 'seed': 15855310, 'workers': True}}}}
2025-03-05 11:13:32,370 INFO    MainThread:2802357 [wandb_run.py:finish():1468] finishing run paolo-lb-fischer-harvard-university/walk-jump-fork/plmxgxno
2025-03-05 11:13:32,370 INFO    MainThread:2802357 [wandb_run.py:_atexit_cleanup():1797] got exitcode: 0
2025-03-05 11:13:32,373 INFO    MainThread:2802357 [wandb_run.py:_restore():1769] restore
2025-03-05 11:13:32,759 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 935
  total_bytes: 935
}

2025-03-05 11:13:32,924 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 935
  total_bytes: 935
}

2025-03-05 11:13:33,432 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 3
}
pusher_stats {
  uploaded_bytes: 935
  total_bytes: 10606
}

2025-03-05 11:13:33,533 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 935
  total_bytes: 21396
}

2025-03-05 11:13:33,634 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 3542
  total_bytes: 21396
}

2025-03-05 11:13:33,735 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 21396
  total_bytes: 21396
}

2025-03-05 11:13:33,836 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 21396
  total_bytes: 21396
}

2025-03-05 11:13:33,937 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 21396
  total_bytes: 21396
}

2025-03-05 11:13:34,037 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 21396
  total_bytes: 21396
}

2025-03-05 11:13:34,336 INFO    MainThread:2802357 [wandb_run.py:_wait_for_finish():1929] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 21396
  total_bytes: 21396
}
local_info {
}

2025-03-05 11:13:35,338 INFO    MainThread:2802357 [wandb_run.py:_append_history():2144] rendering history
2025-03-05 11:13:35,339 INFO    MainThread:2802357 [wandb_run.py:_append_summary():2102] rendering summary
2025-03-05 11:13:35,339 INFO    MainThread:2802357 [wandb_run.py:_append_files():2194] logging synced files
